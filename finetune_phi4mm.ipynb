{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Deep-unlearning/notebooks/blob/main/finetune_phi4mm.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Phi-4 for ASR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will fine-tune pretrained Phi-4-Multimodal-Instruct on a small split of earnings22 test set.\n",
    "\n",
    "Let's get started by installing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub==0.25.2\n",
      "  Using cached huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.2) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.25.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.25.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.25.2) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.25.2) (2024.8.30)\n",
      "Using cached huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.29.2\n",
      "    Uninstalling huggingface-hub-0.29.2:\n",
      "      Successfully uninstalled huggingface-hub-0.29.2\n",
      "Successfully installed huggingface_hub-0.25.2\n",
      "Requirement already satisfied: scipy==1.15.1 in /opt/conda/lib/python3.10/site-packages (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from scipy==1.15.1) (1.25.2)\n",
      "Requirement already satisfied: peft==0.13.2 in /opt/conda/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (4.67.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (1.3.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (0.25.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (2024.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.13.2) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.13.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.13.2) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.13.2) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (2024.8.30)\n",
      "Requirement already satisfied: backoff==2.2.1 in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: transformers==4.46.1 in /opt/conda/lib/python3.10/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.1) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.1) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.1) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.1) (2024.8.30)\n",
      "Requirement already satisfied: accelerate==1.3.0 in /opt/conda/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (0.25.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.3.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.3.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.3.0) (2024.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.3.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.3.0) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.3.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.3.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.3.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.3.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.3.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.3.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.3.0) (2024.8.30)\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.25.2)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: torch==2.6.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Requirement already satisfied: hf_transfer in /opt/conda/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from soundfile) (1.25.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.0)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, click, jiwer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "Successfully installed click-8.1.8 jiwer-3.1.0 rapidfuzz-3.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub==0.25.2\n",
    "!pip install scipy==1.15.1\n",
    "!pip install peft==0.13.2\n",
    "!pip install backoff==2.2.1\n",
    "!pip install transformers==4.46.1\n",
    "!pip install accelerate==1.3.0\n",
    "!pip install sacrebleu\n",
    "!pip install torchvision\n",
    "!pip install hf_transfer\n",
    "!pip install transformers\n",
    "!pip install librosa\n",
    "!pip install soundfile\n",
    "!pip install datasets\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f130d7ac45da4729bf0589296f8c22a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import jiwer\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import gather_object\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoProcessor,\n",
    "    BatchFeature,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    ")\n",
    "\n",
    "# Fixed ASR instruction and other constants\n",
    "INSTRUCTION = \"Transcribe the audio.\"\n",
    "ANSWER_SUFFIX = \"<|end|><|endoftext|>\"\n",
    "_IGNORE_INDEX = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESBEarnings22Dataset(Dataset):\n",
    "    def __init__(self, processor, dataset, training=True):\n",
    "        \"\"\"\n",
    "        processor: the AutoProcessor instance\n",
    "        dataset: a Hugging Face Dataset (already split into train/validation)\n",
    "        training: whether this dataset is for training (affects concatenation of target tokens)\n",
    "        \"\"\"\n",
    "        self.data = dataset\n",
    "        self.training = training\n",
    "        self.processor = processor\n",
    "        self.instruction = INSTRUCTION\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        # The dataset contains an \"audio\" dict and a \"text\" field for transcription.\n",
    "        user_message = {\n",
    "            'role': 'user',\n",
    "            'content': '<|audio_1|>\\n' + self.instruction,\n",
    "        }\n",
    "        prompt = self.processor.tokenizer.apply_chat_template(\n",
    "            [user_message], tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        inputs = self.processor(\n",
    "            text=prompt,\n",
    "            audios=[(data[\"audio\"][\"array\"], data[\"audio\"][\"sampling_rate\"])],\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        answer = f\"{data['text']}{ANSWER_SUFFIX}\"\n",
    "        answer_ids = self.processor.tokenizer(answer, return_tensors='pt').input_ids\n",
    "        if self.training:\n",
    "            # Concatenate prompt and answer, but mask all tokens except the answer.\n",
    "            input_ids = torch.cat([inputs.input_ids, answer_ids], dim=1)\n",
    "            labels = torch.full_like(input_ids, _IGNORE_INDEX)\n",
    "            labels[:, -answer_ids.shape[1]:] = answer_ids\n",
    "        else:\n",
    "            input_ids = inputs.input_ids\n",
    "            labels = answer_ids\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'input_audio_embeds': inputs.input_audio_embeds,\n",
    "            'audio_embed_sizes': inputs.audio_embed_sizes,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequences, padding_side='right', padding_value=0):\n",
    "    assert padding_side in ['right', 'left']\n",
    "    max_size = sequences[0].size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    batch_size = len(sequences)\n",
    "    output = sequences[0].new_full((batch_size, max_len) + trailing_dims, padding_value)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = seq.size(0)\n",
    "        if padding_side == 'right':\n",
    "            output.data[i, :length] = seq\n",
    "        else:\n",
    "            output.data[i, -length:] = seq\n",
    "    return output\n",
    "\n",
    "def cat_with_pad(tensors, dim, padding_value=0):\n",
    "    ndim = tensors[0].dim()\n",
    "    assert all(t.dim() == ndim for t in tensors[1:]), 'All tensors must have the same number of dimensions'\n",
    "    out_size = [max(t.shape[i] for t in tensors) for i in range(ndim)]\n",
    "    out_size[dim] = sum(t.shape[dim] for t in tensors)\n",
    "    output = tensors[0].new_full(out_size, padding_value)\n",
    "    index = 0\n",
    "    for t in tensors:\n",
    "        slices = [slice(0, t.shape[d]) for d in range(ndim)]\n",
    "        slices[dim] = slice(index, index + t.shape[dim])\n",
    "        output[slices] = t\n",
    "        index += t.shape[dim]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esb_collate_fn(batch):\n",
    "    input_ids_list = []\n",
    "    labels_list = []\n",
    "    input_audio_embeds_list = []\n",
    "    audio_embed_sizes_list = []\n",
    "    audio_attention_mask_list = []\n",
    "    for inputs in batch:\n",
    "        input_ids_list.append(inputs['input_ids'][0])\n",
    "        labels_list.append(inputs['labels'][0])\n",
    "        input_audio_embeds_list.append(inputs['input_audio_embeds'])\n",
    "        audio_embed_sizes_list.append(inputs['audio_embed_sizes'])\n",
    "        audio_attention_mask_list.append(\n",
    "            inputs['input_audio_embeds'].new_full((inputs['input_audio_embeds'].size(1),), True, dtype=torch.bool)\n",
    "        )\n",
    "    try:\n",
    "        input_ids = pad_sequence(input_ids_list, padding_side='left', padding_value=0)\n",
    "        labels = pad_sequence(labels_list, padding_side='left', padding_value=0)\n",
    "        audio_attention_mask = (\n",
    "            pad_sequence(audio_attention_mask_list, padding_side='right', padding_value=False)\n",
    "            if len(audio_attention_mask_list) > 1 else None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(input_ids_list)\n",
    "        print(labels_list)\n",
    "        raise\n",
    "    attention_mask = (input_ids != 0).long()\n",
    "    input_audio_embeds = cat_with_pad(input_audio_embeds_list, dim=0)\n",
    "    audio_embed_sizes = torch.cat(audio_embed_sizes_list)\n",
    "    return BatchFeature({\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels,\n",
    "        'attention_mask': attention_mask,\n",
    "        'input_audio_embeds': input_audio_embeds,\n",
    "        'audio_embed_sizes': audio_embed_sizes,\n",
    "        'audio_attention_mask': audio_attention_mask,\n",
    "        'input_mode': 2,  # speech mode\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleTokenBatchStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, stop_tokens: torch.LongTensor, batch_size: int = 1) -> None:\n",
    "        self.stop_tokens = stop_tokens\n",
    "        self.max_stop_tokens = stop_tokens.shape[-1]\n",
    "        self.stop_tokens_idx = torch.zeros(batch_size, dtype=torch.long, device=stop_tokens.device)\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        generated_inputs = torch.eq(input_ids[:, -self.max_stop_tokens :].unsqueeze(1), self.stop_tokens)\n",
    "        equal_generated_inputs = torch.all(generated_inputs, dim=2)\n",
    "        sequence_idx = torch.any(equal_generated_inputs, dim=1)\n",
    "        sequence_set_mask = self.stop_tokens_idx == 0\n",
    "        self.stop_tokens_idx[sequence_idx & sequence_set_mask] = input_ids.shape[-1]\n",
    "        return torch.all(self.stop_tokens_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name_or_path, use_flash_attention=False):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        torch_dtype=torch.bfloat16 if use_flash_attention else torch.float32,\n",
    "        _attn_implementation='flash_attention_2' if use_flash_attention else 'sdpa',\n",
    "        trust_remote_code=True,\n",
    "    ).to('cuda')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, processor, eval_dataset, save_path=None, disable_tqdm=False, eval_batch_size=1):\n",
    "    rank = int(os.environ.get('RANK', 0))\n",
    "    local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "\n",
    "    model.eval()\n",
    "    all_generated_texts = []\n",
    "    all_labels = []\n",
    "\n",
    "    eval_dataloader = torch.utils.data.DataLoader(\n",
    "        eval_dataset,\n",
    "        batch_size=eval_batch_size,\n",
    "        collate_fn=esb_collate_fn,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=8,\n",
    "        prefetch_factor=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    stop_tokens = [\"<|end|>\", processor.tokenizer.eos_token]\n",
    "    stop_tokens_ids = processor.tokenizer(stop_tokens, add_special_tokens=False, padding=\"longest\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "    stop_tokens_ids = stop_tokens_ids.to(f'cuda:{local_rank}')\n",
    "\n",
    "    for inputs in tqdm(eval_dataloader, disable=(rank != 0) or disable_tqdm, desc='running eval'):\n",
    "        stopping_criteria = StoppingCriteriaList([MultipleTokenBatchStoppingCriteria(stop_tokens_ids, batch_size=inputs.input_ids.size(0))])\n",
    "        inputs = inputs.to(f'cuda:{local_rank}')\n",
    "        generated_ids = model.generate(\n",
    "            **inputs, eos_token_id=processor.tokenizer.eos_token_id, max_new_tokens=64,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "        )\n",
    "\n",
    "        stop_tokens_idx = stopping_criteria[0].stop_tokens_idx.reshape(inputs.input_ids.size(0), -1)[:, 0]\n",
    "        stop_tokens_idx = torch.where(\n",
    "            stop_tokens_idx > 0,\n",
    "            stop_tokens_idx - stop_tokens_ids.shape[-1],\n",
    "            generated_ids.shape[-1],\n",
    "        )\n",
    "        generated_text = [\n",
    "            processor.decode(_pred_ids[inputs[\"input_ids\"].shape[1] : _stop_tokens_idx],\n",
    "                               skip_special_tokens=True,\n",
    "                               clean_up_tokenization_spaces=False)\n",
    "            for _pred_ids, _stop_tokens_idx in zip(generated_ids, stop_tokens_idx)\n",
    "        ]\n",
    "        all_generated_texts.extend(generated_text)\n",
    "        labels = [processor.decode(_label_ids[_label_ids != 0]).rstrip(ANSWER_SUFFIX) for _label_ids in inputs[\"labels\"]]\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    all_generated_texts = gather_object(all_generated_texts)\n",
    "    all_labels = gather_object(all_labels)\n",
    "    \n",
    "    if rank == 0:\n",
    "        wer = jiwer.wer(all_labels, all_generated_texts)\n",
    "        print(\"WER:\", wer)\n",
    "        if save_path:\n",
    "            with open(save_path, 'w') as f:\n",
    "                save_dict = {\n",
    "                    'all_generated_texts': all_generated_texts,\n",
    "                    'all_labels': all_labels,\n",
    "                    'wer': wer,\n",
    "                }\n",
    "                json.dump(save_dict, f)\n",
    "        return wer\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "MODEL_NAME = 'microsoft/Phi-4-multimodal-instruct'\n",
    "OUTPUT_DIR = './output/'\n",
    "USE_FLASH_ATTENTION = False\n",
    "BATCH_SIZE_PER_GPU = 2\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "LEARNING_RATE = 4.0e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Initialize Accelerator for potential multi-GPU training.\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Load processor and model\n",
    "with accelerator.local_main_process_first():\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "    model = create_model(MODEL_NAME, use_flash_attention=USE_FLASH_ATTENTION)\n",
    "\n",
    "# Set LoRA adapter (if available) for speech tasks.\n",
    "model.set_lora_adapter('speech')\n",
    "\n",
    "# Load and split the dataset.\n",
    "ds_full = load_dataset(\"AdrienB134/Emilia-dataset-french-split\", split=\"fr\")\n",
    "split_ds = ds_full.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split_ds[\"train\"]\n",
    "val_ds = split_ds[\"test\"]\n",
    "\n",
    "# Create dataset objects.\n",
    "train_dataset = ESBEarnings22Dataset(processor, train_ds, training=True)\n",
    "val_dataset = ESBEarnings22Dataset(processor, val_ds, training=False)\n",
    "\n",
    "num_gpus = accelerator.num_processes\n",
    "print(f\"Training on {num_gpus} GPUs\")\n",
    "\n",
    "# Compute gradient accumulation steps (for multi-GPU training).\n",
    "gradient_accumulation_steps = (BATCH_SIZE_PER_GPU * num_gpus) // BATCH_SIZE_PER_GPU\n",
    "\n",
    "# Set mixed precision flags.\n",
    "fp16 = not USE_FLASH_ATTENTION\n",
    "bf16 = USE_FLASH_ATTENTION\n",
    "\n",
    "# Define training arguments.\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE_PER_GPU,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim='adamw_torch',\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.95,\n",
    "    adam_epsilon=1e-7,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    max_grad_norm=1.0,\n",
    "    lr_scheduler_type='linear',\n",
    "    warmup_steps=50,\n",
    "    logging_steps=10,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_strategy='no',\n",
    "    save_total_limit=10,\n",
    "    save_only_model=True,\n",
    "    bf16=bf16,\n",
    "    fp16=fp16,\n",
    "    remove_unused_columns=False,\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    ddp_find_unused_parameters=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist.\n",
    "Path(training_args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Evaluate the model before fine-tuning.\n",
    "print(\"Evaluating before fine-tuning...\")\n",
    "wer_before = evaluate(\n",
    "    model,\n",
    "    processor,\n",
    "    val_dataset,\n",
    "    save_path=Path(training_args.output_dir) / 'eval_before.json',\n",
    "    eval_batch_size=BATCH_SIZE_PER_GPU,\n",
    ")\n",
    "print(f\"WER before fine-tuning: {wer_before}\")\n",
    "\n",
    "# Setup the Trainer for fine-tuning.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=esb_collate_fn,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "processor.save_pretrained(training_args.output_dir)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory before re-loading the model.\n",
    "del model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reload the fine-tuned model.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    training_args.output_dir,\n",
    "    torch_dtype=torch.bfloat16 if USE_FLASH_ATTENTION else torch.float32,\n",
    "    trust_remote_code=True,\n",
    "    _attn_implementation='flash_attention_2' if USE_FLASH_ATTENTION else 'sdpa',\n",
    ").to('cuda')\n",
    "\n",
    "# Evaluate the model after fine-tuning.\n",
    "print(\"Evaluating after fine-tuning...\")\n",
    "wer_after = evaluate(\n",
    "    model,\n",
    "    processor,\n",
    "    val_dataset,\n",
    "    save_path=Path(training_args.output_dir) / 'eval_after.json',\n",
    "    eval_batch_size=BATCH_SIZE_PER_GPU,\n",
    ")\n",
    "print(f\"WER after fine-tuning: {wer_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push to the hub\n",
    "\n",
    "model.push_to_hub(\"your-username/your-model-name\", commit_message=\"Uploading fine-tuned model\")\n",
    "processor.push_to_hub(\"your-username/your-model-name\", commit_message=\"Uploading processor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WER before finetuning: 0.3346904527379519\n",
    "\n",
    "WER after finetuning: 0.2521907263507351"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
